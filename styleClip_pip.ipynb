{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "styleClip_pip.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/youngseo0526/GoodCasting/blob/master/styleClip_pip.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zw89c67xp3Sr",
        "outputId": "b48e886d-3a76-4b30-a068-59e839dec3df"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otojumi_qKHp"
      },
      "source": [
        "### 필수) 자기 경로로 바꾸기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qusE-X3kEn26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e742b6b-7bcc-4360-90fc-ce582f72eb24"
      },
      "source": [
        "cd /content/drive/MyDrive/Colab Notebooks/NLP_project/GoodCasting/[viper] Latent Optimizer"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/NLP_project/GoodCasting/[viper] Latent Optimizer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ARUvivK7wJP2",
        "outputId": "851e2769-d97d-44c7-9bd6-9a92f8a0362b"
      },
      "source": [
        "pwd"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/Colab Notebooks/NLP_project/GoodCasting/[viper] Latent Optimizer'"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwRMd9BrkHIB",
        "outputId": "bb3ae4bd-c5ed-4024-89fa-3c1376ceed45"
      },
      "source": [
        "!conda env create -f environment.yml"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: conda: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6CUlvlDj0oI",
        "outputId": "0492648d-c4e0-4016-89a4-8863c377537b"
      },
      "source": [
        "!git clone https://github.com/vipermu/StyleCLIP  ## 이미 있으면 안해도 됨"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'StyleCLIP'...\n",
            "remote: Enumerating objects: 30, done.\u001b[K\n",
            "remote: Counting objects: 100% (30/30), done.\u001b[K\n",
            "remote: Compressing objects: 100% (28/28), done.\u001b[K\n",
            "remote: Total 30 (delta 12), reused 9 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (30/30), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkNgsvrBkMra",
        "outputId": "97d991f6-3971-4ec7-caed-0380c85e8674"
      },
      "source": [
        "!pip install git+https://github.com/openai/CLIP.git "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/CLIP.git\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-uphdpfll\n",
            "  Running command git clone -q https://github.com/openai/CLIP.git /tmp/pip-req-build-uphdpfll\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (6.0.3)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (4.62.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (0.11.1+cu111)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy->clip==1.0) (0.2.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->clip==1.0) (3.10.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->clip==1.0) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->clip==1.0) (1.19.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kcQIGgSkepY",
        "outputId": "9cda1fbf-07ba-4ef6-dc85-c1124c95e08f"
      },
      "source": [
        "!python clip_generate.py --prompt \"middle-aged woman has light brown short hair, eyebrows and double eyelids . she has black pupils and wrinkles around her eyes . her nose is round and large .'\""
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"clip_generate.py\", line 10, in <module>\n",
            "    from stylegan_models import g_all, g_synthesis, g_mapping\n",
            "  File \"/content/drive/My Drive/Colab Notebooks/NLP_project/GoodCasting/[viper] Latent Optimizer/stylegan_models.py\", line 381, in <module>\n",
            "    g_all.load_state_dict(torch.load('./karras2019stylegan-ffhq-1024x1024.for_g_all.pt'))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 594, in load\n",
            "    with _open_file_like(f, 'rb') as opened_file:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 230, in _open_file_like\n",
            "    return _open_file(name_or_buffer, mode)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 211, in __init__\n",
            "    super(_open_file, self).__init__(open(name, mode))\n",
            "FileNotFoundError: [Errno 2] No such file or directory: './karras2019stylegan-ffhq-1024x1024.for_g_all.pt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hALPDUUrk8Ck"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}